\documentclass{article}

\begin{document}
\SweaveOpts{concordance=TRUE}

<<>>=
#Upload matrix of RMSF of general PhiPsi values from VMD trajectory
abeta1 <- read.csv("C:/Users/hamrejr/Documents/GMU/Solka/Project/alonDS1903.csv", header = T)


@

Random Forest
<<>>=
library(randomForest)
#PCA 
abeta.pca <- prcomp(abeta1[,3:84], center = TRUE, scale. = TRUE)
#Make dataframe from PC's
df.abeta.x <- as.data.frame(abeta.pca$x)
#Alternatively, one can simply perform RF on phipsi matrix alone
#df.abeta.x <- as.data.frame(abeta1[,3:84])
#Add labels to PC dataframe, alternate classification columns with $
df.abeta.x$groups <- abeta1$grouping
#pca.centroids <- aggregate(df.abeta.x[,3:84], list(Type = df.abeta.x$groups), mean)
#Matrix is usually too big, get a random sample
library(dplyr)
Sample<- sample_n(df.abeta.x[,1:83], 10000)
#Execute RG then print plot of important variables, can set seed for reproducibility or add more trees
set.seed(444)
alon.rf <- randomForest(groups~.,data=Sample,importance=TRUE,ntree=50, proximity=TRUE)
print(alon.rf)
varImpPlot(alon.rf,
            n.var = 25,
            pch=19,
             main= "Random Forest A?? ",
             col="darkgreen",
             gcolor="blue",
             lcolor="black")

@

Euclidean Distance Calculations
<<>>=

###BE SURE TO UPDATE COLUMS USED!!!!!!
#Here we use the top 5-10 PC's generated from the RF output, add 1 to get correct PC, i.e., 2=PC1 Below is an example
#Aggregate the PC's
pca.centroids <- aggregate(df.abeta.x[,1:82], list(Type = df.abeta.x$groups), mean)
#Find the distance
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "A42T",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "D7N",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "A21G",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "E22G",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "L34V",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "E22K",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "E22Q",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "D23N",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "E3D",c(2,3,4,10,13)]), method = "euclidean")
dist(rbind(pca.centroids[pca.centroids$Type == "WT",c(2,3,4,10,13)],pca.centroids[pca.centroids$Type == "E22D",c(2,3,4,10,13)]), method = "euclidean")

@

KNN testing for overall pathogenicity accuracy
<<>>=
#Set column one as P or NP in your dataframe and column two as variant label
library(class)
abeta1 <- read.csv("C:/Users/hamrejr/Project/AbetaPhiPsiRaw.csv", header = T)
#Make dataframe with both types of classifications, pathogenic and specific variant
set.seed(444)
#Separate testing and training data from dataframe, pulling one pathogenic and one non-pathogenic out.
test <- abeta1[abeta1$grouping %in% c("E22D", "A21G"), ] 
train <- abeta1[abeta1$grouping %in% c("WT", "D23N", "E22G", "E3D","L34V","E22K","A42T", "D7N", "E22Q"), ]
#Can use different PC's here
ABtrain <- train[,c(3:78)]
ABtest <- test[,c(3:78)]
#specify class column
target_category <- train[,1]
test_category <- test[,1]
#load the package class
#Run KNN function
set.seed(444)
pr <- knn(ABtrain,ABtest,cl=target_category)
#Create confusion matrix
tab <- table(pr,test_category)
tab
#Accuracy by column calculations 
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)

@

#KNN for yes/no predictions
<<>>=
#Note, this can be performed on RMSF or PhiPsi matrix values, generally unprocessed PhiPsi values gives better KNN separation values but RMSF's give more accurate Euclidean distance values
abeta.pca <- prcomp(abeta1[,3:84], center = TRUE, scale. = TRUE)
#abeta.pca<-prcomp(abeta.data , center = TRUE, scale = TRUE)
df.abeta.x <- as.data.frame(abeta.pca$x)
###CHANGE BEWTWEEN FACTOR AND abeta1$grouping
df.abeta.x$groups <- abeta1$grouping
df.abeta.x$type <- abeta1$phenotype1
pca.centroids <- aggregate(df.abeta.x[,1:82], list(Type = df.abeta.x$type, Groups = df.abeta.x$groups ), mean)
#View the first few PC's and qualitativly evaluate separation, change color based on endpoint, for example, make them all pathogenic red if separating for pathogenicity, make phenotype colors different for which class the variants belong in if this is for disease classification. Note that this can also be performed on a double PCA analysis if centroids are not working well.
pairs(pca.centroids[,3:8], col= c("red", "red", "red", "red", "grey", "red","red","red", "grey", "red", "green") , pch=17, main = "Pairs Plot Amyloid Beta" )
#Here we only pull out 1 at a time
test <- pca.centroids[pca.centroids$Groups%in% c("A21G"), ] 
train <- pca.centroids[pca.centroids$Groups%in% c(  "L34V", "D23N","D7N", "E22K", "A42T", "E22Q",  "E22G", "E22D", "E3D","WT"), ]
abeta_train <- train[,c(3:7)]
abeta_test <- test[,c(3:7)]
abeta_target_category <- train[,1]
abeta_test_category <- test[,1]
##run KNN function
set.seed(444)
predicted <- knn(abeta_train,abeta_test,cl=abeta_target_category)
#Create confusion matrix
tab <- table(predicted,abeta_test_category)
library(caret)
# Generate confusion matrix
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
tab

@



3D Graph
<<>>=
library(rgl)
library(car)
##Right click and drag to label
##PCA
abeta.pca <- prcomp(abeta1[,c(3:84)], center = TRUE, scale. = TRUE)
#MAKE DATA FRAME FROM PC'S
df.abeta.x$groups <- abeta1$grouping
df.abeta.x <- as.data.frame(abeta.pca$x)

pca.centroids <- aggregate(df.abeta.x[,1:82], list(Type = df.abeta.x$groups), mean)
###CHANGE BEWTWEEN FACTOR AND abeta1$grouping
pairs(pca.centroids[,2:7], col= c("red", "red", "blue", "red", "grey", "red","blue","blue", "grey", "blue", "green") , pch=17 )
df.abeta.x$groups <- abeta1$grouping
#write.csv(df.abeta.x,"C:/Users/hamrejr/Documents/GMU/Project/df.abeta.csv")
#from Eucl Dist
pca.centroids <- aggregate(df.abeta.x[,1:82], list(Type = df.abeta.x$groups), mean)
 x = pca.centroids[, 6
]
 y = pca.centroids[, 7
]
 z = pca.centroids[, 10
]

shapes <- (as.numeric(0,0,1,2,0,0,1,1,2,1,3))

scatter3d(x,y,z ,point.col = c("blue", "blue", "red", "white","blue", "blue", "red","red","white","red","green") ,    surface = FALSE,  grid = TRUE, pch=shapes)


Identify3d(x, y, z, axis.scales=TRUE, groups = NULL, labels = c("A21G", "A42T", "D23N", "E22D", "D7N","E22G", "E22K", "E22Q", "E3D", "L34V", "WT"),
	offset = ((100/length(x))^(1/1.5)) * 0.02, col = "black")
#rgl.postscript("persp3dd4.pdf","pdf")

@




\end{document}